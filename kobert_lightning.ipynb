{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이트닝 참고\n",
    "\n",
    "https://baeseongsu.github.io/posts/pytorch-lightning-introduction/ - train/val step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader , Dataset , TensorDataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import BertModel\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RM_bert(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 하이퍼 파라미터\n",
    "        self.num_labels=1\n",
    "        self.hidden_size=768\n",
    "        self.hidden_dropout_prob=0.1\n",
    "\n",
    "        # 모델 구조\n",
    "        self.kobert = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "        self.dropout = nn.Dropout(self.hidden_dropout_prob)\n",
    "        self.linear = nn.Linear(self.hidden_size,  self.num_labels)\n",
    "\n",
    "        # 최적화 파라미터\n",
    "        #self.ratio_pn = 1 # T/F 비율 얼마나 줄지 ex) T 10개 F 30개면 pos_weight = 3\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()   # sigmoid+BCE\n",
    "\n",
    "    def forward(\n",
    "            self,input_ids=None,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=None,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            inputs_embeds=None,\n",
    "            labels=None,\n",
    "            ):\n",
    "        \n",
    "        # KoBERT 입력\n",
    "        output = self.kobert(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            )\n",
    "        \n",
    "        # 드롭아웃\n",
    "        pooled_output = self.dropout(output.pooler_output)\n",
    "\n",
    "        # 리니어 레이어\n",
    "        return self.linear(pooled_output)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(),lr=0.02)\n",
    "    \n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x1,x2,x3,y = train_batch['x1'] , train_batch['x2'] , train_batch['x3'] , train_batch['y']\n",
    "        logits = self.forward(x1,x2,x3)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        self.log_dict({'train_loss':loss})\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x1,x2,x3,y = val_batch['x1'] , val_batch['x2'] , val_batch['x3'] , val_batch['y']\n",
    "        logits = self.forward(x1,x2,x3)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        self.log_dict({'val_loss':loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "class News_Dataset(Dataset):\n",
    "    def __init__(self,root_path):\n",
    "        true_path = os.path.join(root_path,str(1))\n",
    "        #false_path = os.path.join(root_path,str(0))\n",
    "        true_file_list = [os.path.join(true_path,f) for f in os.listdir(true_path)]\n",
    "        #false_file_list = [os.path.join(false_path,f) for f in os.listdir(false_path)]\n",
    "\n",
    "        # 최종 파일경로 모음 및 라벨\n",
    "        self.file_path = true_file_list #+ false_file_list\n",
    "        self.label = [1 for _ in range(len(true_file_list))] #+ [0 for _ in range(len(false_file_list))]\n",
    "\n",
    "        # 섞어주기\n",
    "        data = list(zip(self.file_path, self.label))\n",
    "        random.shuffle(data)\n",
    "        self.file_path, self.label = zip(*data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.file_path[idx], 'r') as file:\n",
    "            title = file.readline().rstrip('\\n')\n",
    "            content = file.readline()\n",
    "        y = self.label[idx]\n",
    "        return {'x':[title,content] , 'y': torch.tensor(y)}\n",
    "\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def my_collate_fn(samples):\n",
    "    '''\n",
    "        [{'x':[title_1,content_1] , 'y' : tensor([y1])},\n",
    "         {'x':[title_2,content_2] , 'y' : tensor([y2])} ... ]\n",
    "    \n",
    "    '''\n",
    "\n",
    "    collate_x = [sample['x'] for sample in samples]\n",
    "    collate_y = [sample['y'] for sample in samples]\n",
    "    \n",
    "    tokenized_x = data_collator(tokenizer.batch_encode_plus(collate_x))\n",
    "\n",
    "    return {'x1': tokenized_x.input_ids,\n",
    "            'x2' : tokenized_x.token_type_ids,\n",
    "            'x3' : tokenized_x.attention_mask,\n",
    "            'y': torch.stack(collate_y)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = News_Dataset('./Dataset')\n",
    "d_l = len(train_dataset)\n",
    "train_dataset, valid_dataset, test_dataset = random_split(train_dataset,[int(0.8*d_l),int(0.1*d_l),int(0.1*d_l)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | kobert  | BertModel         | 92.2 M\n",
      "1 | dropout | Dropout           | 0     \n",
      "2 | linear  | Linear            | 769   \n",
      "3 | loss_fn | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------\n",
      "92.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "92.2 M    Total params\n",
      "368.751   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54616300e8bf438ea385c4ba5c1ed02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (586) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\minki\\Desktop\\Bigkinds_news_competition\\kobert_lightning.ipynb 셀 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,logger\u001b[39m=\u001b[39mlogger,accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                      \u001b[39m#callbacks=checkpoint_callback\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                      )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model \u001b[39m=\u001b[39m RM_bert()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model,train_loader,valid_loader)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:531\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    529\u001b[0m model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 531\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    532\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    533\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     44\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     45\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:570\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[0;32m    561\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[0;32m    562\u001b[0m )\n\u001b[0;32m    564\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    565\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    566\u001b[0m     ckpt_path,\n\u001b[0;32m    567\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    568\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m )\n\u001b[1;32m--> 570\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    572\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    573\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:975\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    972\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    980\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1016\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m   1015\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1016\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[0;32m   1017\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1018\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1045\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1042\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1044\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1045\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1047\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1049\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[0;32m    176\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m     previous_dataloader_idx \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m    114\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[0;32m    116\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:375\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[0;32m    374\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 375\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39;49mstep_kwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m    377\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[0;32m    379\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_test_batch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mon_validation_batch_end\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:287\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 287\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    290\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:379\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m    378\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 379\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mvalidation_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\minki\\Desktop\\Bigkinds_news_competition\\kobert_lightning.ipynb 셀 6\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, val_batch, batch_idx):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     x1,x2,x3,y \u001b[39m=\u001b[39m val_batch[\u001b[39m'\u001b[39m\u001b[39mx1\u001b[39m\u001b[39m'\u001b[39m] , val_batch[\u001b[39m'\u001b[39m\u001b[39mx2\u001b[39m\u001b[39m'\u001b[39m] , val_batch[\u001b[39m'\u001b[39m\u001b[39mx3\u001b[39m\u001b[39m'\u001b[39m] , val_batch[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x1,x2,x3)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(logits, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_dict({\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m:loss})\n",
      "\u001b[1;32mc:\\Users\\minki\\Desktop\\Bigkinds_news_competition\\kobert_lightning.ipynb 셀 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39mself\u001b[39m,input_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         token_type_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# KoBERT 입력\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkobert(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         input_ids,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m# 드롭아웃\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobert_lightning.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(output\u001b[39m.\u001b[39mpooler_output)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[0;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1016\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1017\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[0;32m   1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[0;32m   1021\u001b[0m     embedding_output,\n\u001b[0;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:236\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    235\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)\n\u001b[1;32m--> 236\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_embeddings\n\u001b[0;32m    237\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)\n\u001b[0;32m    238\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (586) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "train_loader =  DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=0,collate_fn=my_collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset,batch_size=batch_size,shuffle=False,num_workers=0,collate_fn=my_collate_fn)\n",
    "\n",
    "logger = pl.loggers.CSVLogger(\"logs\", name=\"RM_training1\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=10,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    #dirpath=\"my/path/\",\n",
    "    filename=\"sample-mnist-{epoch:02d}-{val_loss:.2f}\",\n",
    ")\n",
    "trainer = pl.Trainer(max_epochs=2,logger=logger,accelerator=\"auto\",\n",
    "                     #callbacks=checkpoint_callback\n",
    "                     )\n",
    "model = RM_bert()\n",
    "trainer.fit(model,train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제\n",
    "\n",
    "0. 크롤링 기사 전처리 , 제목 , 본문 어떻게 할건지? , 스페셜 토큰\n",
    "\n",
    "1. 다이나믹 패딩 collate에 적용\n",
    "\n",
    "2. 얼마나 저장할지 에퐄마다?\n",
    "\n",
    "3. 조기종료\n",
    "\n",
    "4. 스케줄러? 안해도 될듯? 몰루\n",
    "\n",
    "5. py파일로 변환 , arg 밑 도커 백그라운드\n",
    "\n",
    "6. train_loss는 왜 저장안되는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loader = DataLoader(News_Dataset(),batch_size=10,shuffle=True,collate_fn=my_collate_fn)\n",
    "sample = next(iter(test_loader))\n",
    "x1,x2,x3,y = sample['x1'] , sample['x2'] , sample['x3'] , sample['y']\n",
    "y_pred = nn.Sigmoid()(model(x1,x2,x3))\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "\n",
    "true_path = os.path.join('./Dataset',str(1))\n",
    "true_file_list = [os.path.join(true_path,f) for f in os.listdir(true_path)]\n",
    "\n",
    "len_list = []\n",
    "\n",
    "for file_path in true_file_list:\n",
    "    with open(file_path, 'r') as file:\n",
    "        title = file.readline().rstrip('\\n')\n",
    "        content = file.readline()\n",
    "    len_list.append(len(tokenizer.encode(title,content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 2., 4., ..., 0., 0., 1.]),\n",
       " array([   5.,    6.,    7., ..., 3370., 3371., 3372.]),\n",
       " <BarContainer object of 3367 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(len_list, bins=range(min(len_list), max(len_list) + 1), edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
