{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoBART 분류 참고\n",
    "\n",
    "https://github.com/SKT-AI/KoBART/blob/main/examples/nsmc.py#L226"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader , Dataset , TensorDataset\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import BartModel\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "\n",
    "from kobart import get_kobart_tokenizer, get_pytorch_kobart_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RM_Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bart = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
    "\n",
    "        self.linear_1 = nn.Linear(768,  768)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear_2 = nn.Linear(768,  1)\n",
    "\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([8.1])) \n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bart(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        eos_mask = input_ids.eq(1).to(hidden_states.device)\n",
    "        sentence_representation = hidden_states[eos_mask, :].view(hidden_states.size(0), -1, hidden_states.size(-1))[:, -1, :]\n",
    "        logits = self.linear_2(self.dropout(self.linear_1(sentence_representation)))\n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = self.loss_fn(logits, batch[\"labels\"])\n",
    "        self.log_dict({'loss':loss})\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = self.loss_fn(logits, batch[\"labels\"])\n",
    "        self.log_dict({'val_loss':loss})\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(),lr=0.02)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\Users\\minki\\Desktop\\Bigkinds_news_competition\\.cache\\kobart_base_tokenizer_cased_cf74400bce.zip\n"
     ]
    }
   ],
   "source": [
    "class News_Dataset(Dataset):\n",
    "    def __init__(self,root_path):\n",
    "        true_path = os.path.join(root_path,str(1))\n",
    "        false_path = os.path.join(root_path,str(0))\n",
    "\n",
    "        true_file_list = [os.path.join(true_path,f) for f in os.listdir(true_path)]\n",
    "        false_file_list = [os.path.join(false_path,f) for f in os.listdir(false_path)]\n",
    "\n",
    "        # 최종 파일경로 모음 및 라벨\n",
    "        self.file_path = true_file_list + false_file_list\n",
    "        self.label = [1 for _ in range(len(true_file_list))] + [0 for _ in range(len(false_file_list))]\n",
    "\n",
    "        # 섞어주기\n",
    "        data = list(zip(self.file_path, self.label))\n",
    "        random.shuffle(data)\n",
    "        self.file_path, self.label = zip(*data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.file_path[idx], 'r') as file:\n",
    "            title = file.readline().rstrip('\\n')\n",
    "            content = file.readline()\n",
    "\n",
    "        return {'x':'<s>'+title+'<unused0>'+content+'</s>' , 'y': torch.tensor([self.label[idx]],dtype=torch.float)}\n",
    "\n",
    "\n",
    "tokenizer = tokenizer = get_kobart_tokenizer()\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def my_collate_fn(samples):\n",
    "    '''\n",
    "        [{'x':[\"<s>title_1<unused0>content_1</s>\"] , 'y' : tensor([y1])},\n",
    "         {'x':[\"<s>title_2<unused0>content_2</s>\"] , 'y' : tensor([y2])} ... ]\n",
    "    \n",
    "    '''\n",
    "\n",
    "    collate_y = [sample['y'] for sample in samples]\n",
    "    collate_x = [sample['x'] for sample in samples]\n",
    "\n",
    "    tokenized_x = data_collator(tokenizer.batch_encode_plus(collate_x))\n",
    "\n",
    "    return {'input_ids': tokenized_x.input_ids,\n",
    "            'attention_mask' : tokenized_x.attention_mask,\n",
    "            'labels': torch.stack(collate_y)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29934, 3300, 3300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = News_Dataset('./Dataset/train')\n",
    "valid_dataset = News_Dataset('./Dataset/val')\n",
    "test_dataset = News_Dataset('./Dataset/test')\n",
    "len(train_dataset) , len(valid_dataset) , len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\Users\\minki\\Desktop\\Bigkinds_news_competition\\.cache\\kobart_base_cased_ff4bda5738.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: logs\\RM_training1\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type              | Params\n",
      "-----------------------------------------------\n",
      "0 | bart     | BartModel         | 123 M \n",
      "1 | linear_1 | Linear            | 590 K \n",
      "2 | dropout  | Dropout           | 0     \n",
      "3 | linear_2 | Linear            | 769   \n",
      "4 | loss_fn  | BCEWithLogitsLoss | 0     \n",
      "-----------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "497.805   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3aa51507d1e46219571356c57f625ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e3ab2d17984ec4abde3329f9614bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7defa5650243a994a6a733d9fd8d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "train_loader =  DataLoader(train_dataset,batch_size=batch_size,shuffle=True,collate_fn=my_collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset,batch_size=batch_size,shuffle=False,collate_fn=my_collate_fn)\n",
    "\n",
    "\n",
    "logger = pl.loggers.CSVLogger(\"logs\", name=\"RM_training1\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=5,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    filename=\"RM_Model-{epoch:02d}-{val_loss:.2f}\",\n",
    ")\n",
    "trainer = pl.Trainer(max_epochs=1,logger=logger,accelerator=\"auto\",\n",
    "                     callbacks=checkpoint_callback,\n",
    "                     log_every_n_steps=10\n",
    "                     )\n",
    "model = RM_Model()\n",
    "trainer.fit(model,train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"1epoch.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\Users\\minki\\Desktop\\Bigkinds_news_competition\\.cache\\kobart_base_cased_ff4bda5738.zip\n"
     ]
    }
   ],
   "source": [
    "model = RM_Model.load_from_checkpoint(\"1epoch.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=10, correct_bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제\n",
    "\n",
    "0. 크롤링 기사 전처리 , 제목 , 본문 어떻게 할건지? , 스페셜 토큰\n",
    "\n",
    "1. 다이나믹 패딩 collate에 적용\n",
    "\n",
    "2. 얼마나 저장할지 에퐄마다?\n",
    "\n",
    "3. 조기종료\n",
    "\n",
    "4. 스케줄러? 안해도 될듯? 몰루\n",
    "\n",
    "5. py파일로 변환 , arg 밑 도커 백그라운드\n",
    "\n",
    "6. train_loss는 왜 저장안되는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 : 모델 => 0.0 : -1.909703254699707\n",
      "실제 : 모델 => 1.0 : -1.909703254699707\n",
      "실제 : 모델 => 0.0 : -1.9097037315368652\n",
      "실제 : 모델 => 0.0 : -1.9097037315368652\n",
      "실제 : 모델 => 0.0 : -1.909703254699707\n",
      "실제 : 모델 => 0.0 : -1.909703254699707\n",
      "실제 : 모델 => 0.0 : -1.909703254699707\n",
      "실제 : 모델 => 0.0 : -1.9097027778625488\n",
      "실제 : 모델 => 0.0 : -1.9097037315368652\n",
      "실제 : 모델 => 0.0 : -1.909703254699707\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\minki\\Desktop\\Bigkinds_news_competition\\kobart_lightning.ipynb 셀 14\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(test_dataset,batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,collate_fn\u001b[39m=\u001b[39mmy_collate_fn)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m test_data \u001b[39min\u001b[39;00m test_loader:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     logit \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(test_data[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m], test_data[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m#logit = nn.Sigmoid()(logit)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m실제 : 모델 => \u001b[39m\u001b[39m{\u001b[39;00mtest_data[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m : \u001b[39m\u001b[39m{\u001b[39;00mlogit\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\minki\\Desktop\\Bigkinds_news_competition\\kobart_lightning.ipynb 셀 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbart(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlast_hidden_state\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minki/Desktop/Bigkinds_news_competition/kobart_lightning.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     eos_mask \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39meq(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(hidden_states\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1255\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1249\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[0;32m   1250\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1251\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1254\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1255\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[0;32m   1256\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[0;32m   1257\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[0;32m   1258\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_outputs[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m   1259\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1260\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[0;32m   1261\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[0;32m   1262\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1263\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[0;32m   1264\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1265\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1266\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1267\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1268\u001b[0m )\n\u001b[0;32m   1270\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1271\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs \u001b[39m+\u001b[39m encoder_outputs\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1113\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m   1103\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[0;32m   1104\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1111\u001b[0m     )\n\u001b[0;32m   1112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1113\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[0;32m   1114\u001b[0m         hidden_states,\n\u001b[0;32m   1115\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1116\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1117\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1118\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1119\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49m(\n\u001b[0;32m   1120\u001b[0m             cross_attn_head_mask[idx] \u001b[39mif\u001b[39;49;00m cross_attn_head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m   1121\u001b[0m         ),\n\u001b[0;32m   1122\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m   1123\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1124\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1125\u001b[0m     )\n\u001b[0;32m   1126\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:445\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m    444\u001b[0m cross_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 445\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_attn(\n\u001b[0;32m    446\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m    447\u001b[0m     key_value_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    448\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m    449\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[0;32m    450\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mcross_attn_past_key_value,\n\u001b[0;32m    451\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    452\u001b[0m )\n\u001b[0;32m    453\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m    454\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:275\u001b[0m, in \u001b[0;36mBartAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    271\u001b[0m     attn_weights_reshaped \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    273\u001b[0m attn_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(attn_weights, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m--> 275\u001b[0m attn_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbmm(attn_probs, value_states)\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m attn_output\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m (bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim):\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`attn_output` should be of size \u001b[39m\u001b[39m{\u001b[39;00m(bsz\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\u001b[39m \u001b[39mtgt_len,\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\u001b[39m}\u001b[39;00m\u001b[39m, but is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mattn_output\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loader = DataLoader(test_dataset,batch_size=1,shuffle=True,collate_fn=my_collate_fn)\n",
    "for test_data in test_loader:\n",
    "    logit = model.forward(test_data[\"input_ids\"], test_data[\"attention_mask\"])\n",
    "    #logit = nn.Sigmoid()(logit)\n",
    "    print(f\"실제 : 모델 => {test_data['labels'].item()} : {logit.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
